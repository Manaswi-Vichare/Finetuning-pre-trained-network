{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Finetuning a pre-trained network and the optimizers"
      ],
      "metadata": {
        "id": "CxX3-XszEOF-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-8Q5QjmkBJi5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from torchvision.models import ResNet101_Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "EN3jqPQUEjJw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10(root='./data', split='train', download=True, transform=transform)\n",
        "test_dataset = datasets.STL10(root='./data', split='test', download=True, transform=transform)\n",
        "num_classes = 10\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01uXv7hBEnkD",
        "outputId": "691f807f-d925-4b5c-fc5d-fa317d2866b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [05:17<00:00, 8320906.09it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet101(pretrained=True)"
      ],
      "metadata": {
        "id": "cjhfNfvNErav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f79ecd0-03d1-4273-8fb2-f839a40ac84e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 159MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, num_classes)"
      ],
      "metadata": {
        "id": "Hs1L-ZxBEwhs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model():\n",
        "    weights = ResNet101_Weights.DEFAULT\n",
        "    model = torchvision.models.resnet101(weights=weights)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ap4zkU8S5-Vd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "3OM0gy_rFI5A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "dsNbUpG1V6de"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(optimizer, model, criterion, train_loader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100. * correct / total\n",
        "\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "r7D-3dQAE7fR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, criterion, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            all_predictions.extend(outputs.cpu().numpy())\n",
        "            all_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_acc = 100. * correct / total\n",
        "\n",
        "    return test_acc, torch.tensor(all_predictions), torch.tensor(all_targets)"
      ],
      "metadata": {
        "id": "5LtAWXq8FCg_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer 1: Adam; Optimizer 2: Adagrad; Optimizer 3: Adadelta"
      ],
      "metadata": {
        "id": "v-MTH-HdRlkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [\n",
        "    lambda params: optim.Adam(params, lr=0.001),\n",
        "    lambda params: optim.Adagrad(params, lr=0.01),\n",
        "    lambda params: optim.Adadelta(params, lr=1.0),\n",
        "]"
      ],
      "metadata": {
        "id": "-9VYMWs74R_k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, optimizer_fn in enumerate(optimizers):\n",
        "    model = initialize_model()\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optimizer_fn(model.parameters())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train(optimizer, model, criterion, train_loader, device)\n",
        "        test_acc, test_predictions, test_targets = test(model, criterion, test_loader, device)\n",
        "        top_5_accuracy = top_k_accuracy_score(test_targets, test_predictions, k=5)\n",
        "\n",
        "        print(f\"Optimizer {i+1}, Epoch [{epoch+1}/{num_epochs}], \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
        "              f\"Test Acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "6156fsS5FNaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555ff4e1-29d7-4b93-b527-062b9a8b1bd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 163MB/s]\n",
            "<ipython-input-10-2f576e7c3658>:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return test_acc, torch.tensor(all_predictions), torch.tensor(all_targets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer 1, Epoch [1/10], Train Loss: 0.7274, Train Acc: 76.90%, Test Acc: 81.66%\n",
            "Optimizer 1, Epoch [2/10], Train Loss: 0.3967, Train Acc: 86.86%, Test Acc: 78.79%\n",
            "Optimizer 1, Epoch [3/10], Train Loss: 0.3223, Train Acc: 89.46%, Test Acc: 81.22%\n",
            "Optimizer 1, Epoch [4/10], Train Loss: 0.2351, Train Acc: 92.10%, Test Acc: 85.49%\n",
            "Optimizer 1, Epoch [5/10], Train Loss: 0.1292, Train Acc: 95.38%, Test Acc: 83.54%\n",
            "Optimizer 1, Epoch [6/10], Train Loss: 0.1287, Train Acc: 95.62%, Test Acc: 83.06%\n",
            "Optimizer 1, Epoch [7/10], Train Loss: 0.1164, Train Acc: 96.22%, Test Acc: 82.21%\n",
            "Optimizer 1, Epoch [8/10], Train Loss: 0.1135, Train Acc: 96.30%, Test Acc: 78.34%\n",
            "Optimizer 1, Epoch [9/10], Train Loss: 0.1030, Train Acc: 96.76%, Test Acc: 84.47%\n",
            "Optimizer 1, Epoch [10/10], Train Loss: 0.1250, Train Acc: 95.68%, Test Acc: 80.78%\n",
            "Optimizer 2, Epoch [1/10], Train Loss: 1.9960, Train Acc: 22.86%, Test Acc: 24.82%\n",
            "Optimizer 2, Epoch [2/10], Train Loss: 1.5612, Train Acc: 37.84%, Test Acc: 35.54%\n",
            "Optimizer 2, Epoch [3/10], Train Loss: 1.2570, Train Acc: 52.56%, Test Acc: 52.50%\n",
            "Optimizer 2, Epoch [4/10], Train Loss: 0.9654, Train Acc: 65.16%, Test Acc: 37.00%\n",
            "Optimizer 2, Epoch [5/10], Train Loss: 0.7311, Train Acc: 73.40%, Test Acc: 57.64%\n",
            "Optimizer 2, Epoch [6/10], Train Loss: 0.5255, Train Acc: 81.58%, Test Acc: 59.84%\n",
            "Optimizer 2, Epoch [7/10], Train Loss: 0.3578, Train Acc: 87.50%, Test Acc: 69.59%\n",
            "Optimizer 2, Epoch [8/10], Train Loss: 0.2186, Train Acc: 92.54%, Test Acc: 71.47%\n",
            "Optimizer 2, Epoch [9/10], Train Loss: 0.1202, Train Acc: 96.12%, Test Acc: 75.24%\n",
            "Optimizer 2, Epoch [10/10], Train Loss: 0.0772, Train Acc: 97.80%, Test Acc: 73.24%\n",
            "Optimizer 3, Epoch [1/10], Train Loss: 0.6939, Train Acc: 77.34%, Test Acc: 47.25%\n",
            "Optimizer 3, Epoch [2/10], Train Loss: 0.3796, Train Acc: 86.90%, Test Acc: 71.89%\n",
            "Optimizer 3, Epoch [3/10], Train Loss: 0.2251, Train Acc: 92.50%, Test Acc: 81.26%\n",
            "Optimizer 3, Epoch [4/10], Train Loss: 0.1553, Train Acc: 94.86%, Test Acc: 21.69%\n",
            "Optimizer 3, Epoch [5/10], Train Loss: 0.0845, Train Acc: 97.10%, Test Acc: 85.74%\n",
            "Optimizer 3, Epoch [6/10], Train Loss: 0.0412, Train Acc: 98.68%, Test Acc: 74.55%\n",
            "Optimizer 3, Epoch [7/10], Train Loss: 0.0782, Train Acc: 97.48%, Test Acc: 74.42%\n",
            "Optimizer 3, Epoch [8/10], Train Loss: 0.0770, Train Acc: 97.28%, Test Acc: 86.88%\n",
            "Optimizer 3, Epoch [9/10], Train Loss: 0.0454, Train Acc: 98.58%, Test Acc: 89.75%\n",
            "Optimizer 3, Epoch [10/10], Train Loss: 0.0416, Train Acc: 98.50%, Test Acc: 86.09%\n"
          ]
        }
      ]
    }
  ]
}